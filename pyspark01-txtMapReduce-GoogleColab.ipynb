{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark01 - txtMapReduce - GoogleColab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "z91iSn39PQnv"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grfgrf/exercicios/blob/main/pyspark01-txtMapReduce-GoogleColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z91iSn39PQnv"
      },
      "source": [
        "#Download/instalação dependências Spark/Pyspark\n",
        "*primeira run aprox 60segundos\n",
        "\n",
        "1.   apt-get openjdk-8-jdk-headless\n",
        "2.   download spark-3.2.0-bin-hadoop3.2.tgz\n",
        "3.   unzip spark-3.2.0-bin-hadoop3.2    \n",
        "4.   download sherlock.txt\n",
        "5.   pip install findspark (pyspark)\n",
        "6.   set JAVA_HOME e SPARK_HOME paths\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp6i4txWWMw-",
        "outputId": "dd54bc1f-cb94-4fe9-dbfa-d778b1d4f2e9"
      },
      "source": [
        "%%bash\n",
        "#***IFs apenas para o notebook não executar novamente em caso de run all cells.\n",
        "\n",
        "#verifica se openjdk está instalado\n",
        "if (dpkg -l | grep -qw openjdk-8-jdk-headless) then \n",
        "  echo \"Ja instalado - openjdk-8-jdk-headless\" \n",
        "else \n",
        "  apt-get install openjdk-8-jdk-headless -qq > /dev/null | echo \"openjdk-8-jdk-headless - instalado com sucesso\" \n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk-8-jdk-headless - instalado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKWPErew7HHg",
        "outputId": "645f7f83-6961-4ac3-c50d-63ce25a732da"
      },
      "source": [
        "%%bash\n",
        "#download spark-hadoop\n",
        "if [ -f \"spark-3.2.0-bin-hadoop3.2.tgz\" ]; then\n",
        "  echo \"Ja baixado - spark-3.2.0-bin-hadoop3.2.tgz\"\n",
        "else \n",
        "  wget -q  https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz | echo \"spark-3.2.0-bin-hadoop3.2.tgz - baixado com sucesso\"\n",
        "fi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.0-bin-hadoop3.2.tgz - baixado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnOz9fC7HQ2",
        "outputId": "8d3d0d60-e8aa-4806-a4b3-779d37a71e65"
      },
      "source": [
        "%%bash\n",
        "#extrair spark-hadoop\n",
        "if [ -d \"spark-3.2.0-bin-hadoop3.2\" ]; then\n",
        "  echo \"Ja descompactado - Pasta spark-3.2.0-bin-hadoop3.2\"\n",
        "else \n",
        "  tar xf spark-3.2.0-bin-hadoop3.2.tgz | echo \"spark-3.2.0-bin-hadoop3.2.tgz - descompactado com sucesso\"\n",
        "fi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.0-bin-hadoop3.2.tgz - descompactado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VIRCV5z7Hb0",
        "outputId": "ccc841a5-9b0c-48a7-b0b5-e7160e1286a3"
      },
      "source": [
        "%%bash\n",
        "#download sherlock.txt\n",
        "if [ -f \"/content/sample_data/sherlock.txt\" ]; then\n",
        "  echo \"Ja baixado - sherlock.txt\"\n",
        "else \n",
        "  wget -q -O /content/sample_data/sherlock.txt https://www.gutenberg.org/files/1661/1661-0.txt | echo \"sherlock.txt - baixado com sucesso\"\n",
        "fi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sherlock.txt - baixado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht_iWNwOPqrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca0f06a-8785-4cc5-bca8-ecd531087aec"
      },
      "source": [
        "#usa folder do spark como lib pyspark\n",
        "try:\n",
        "    findspark\n",
        "except NameError:\n",
        "    !pip install -q findspark\n",
        "    import findspark\n",
        "    findspark.init('spark-3.2.0-bin-hadoop3.2')\n",
        "    print(\"findspark - instalado com sucesso \")\n",
        "else:\n",
        "    print(\"já instalado - findspark\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "findspark - instalado com sucesso \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWvBZvULP8bV"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRUzdhgTQ2lN"
      },
      "source": [
        "#Spark .txt RDD ou DataFrame pronto para ser manipulado abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7h1_G0zBLbZ"
      },
      "source": [
        "#cria session e lê sherlock como .rdd\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "\n",
        "#dataframe\n",
        "txtDF = spark.read.format('text').load('/content/sample_data/sherlock.txt')\n",
        "\n",
        "#RDD\n",
        "txtRDD= spark.read.format('text').load('/content/sample_data/sherlock.txt').rdd\n",
        "\n",
        "#Texto inteiro em RDD com 1 row [k,v]\n",
        "rddSherlock = spark.sparkContext.wholeTextFiles('/content/sample_data/sherlock.txt',use_unicode=True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s_U1mQtEZQ_",
        "outputId": "e3b60f6c-8532-492b-acab-891fbbeb70c4"
      },
      "source": [
        "txtDF.head(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='The Project Gutenberg eBook of The Adventures of Sherlock Holmes, by Arthur Conan Doyle'),\n",
              " Row(value='')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLUTxmGHUhLM",
        "outputId": "d6a63ded-3ad1-4e94-985d-aad15b48845b"
      },
      "source": [
        "txtRDD.take(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='The Project Gutenberg eBook of The Adventures of Sherlock Holmes, by Arthur Conan Doyle'),\n",
              " Row(value='')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEClBJC9w-n_"
      },
      "source": [
        "#Mapeia só [\\W]+ lower case\n",
        "import re\n",
        "\n",
        "mapSherlock = rddSherlock.map(lambda x : re.sub(r\"[\\W]+\",\" \",x[1].lower()))\n",
        "#mapSherlock.take(1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is3P5Fs8-crA",
        "outputId": "6712ed26-9bed-4cd0-d322-c86f1e2c4335"
      },
      "source": [
        "#Split por espaço em branco\n",
        "palavrasSherlock = mapSherlock.flatMap(lambda x: x.split(\" \"))\n",
        "palavrasSherlock.take(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'the', 'project', 'gutenberg', 'ebook']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC-iiDyKx_on",
        "outputId": "5d93fb7f-8637-4755-fd3a-0bd5ca602808"
      },
      "source": [
        "#Adiciona coluna com valor 1 para reduce\n",
        "formatadoSherlock = palavrasSherlock.map(lambda z: (z,1)) \n",
        "formatadoSherlock.take(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 1), ('the', 1), ('project', 1), ('gutenberg', 1), ('ebook', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X33OFau2ydi1",
        "outputId": "895b40bc-ca2f-4f53-f156-512a804c626e"
      },
      "source": [
        "# RDD final com ReduceByKey (reduz keys iguais e soma values)\n",
        "finalSherlock = formatadoSherlock.reduceByKey(lambda a,b: a+b)\n",
        "finalSherlock.take(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 2), ('the', 5815), ('project', 89), ('gutenberg', 98), ('ebook', 13)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2jOqG9ZyxPp",
        "outputId": "85f61b14-6ecf-4397-96e2-3c1c1bbf30e1"
      },
      "source": [
        "#lista TOP 10 sorted\n",
        "#contagem final depende da regra para definir \"O que é uma palavra?\"\n",
        "finalSherlock.sortBy(lambda x: x[1],ascending=False).collect()[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 5815),\n",
              " ('and', 3085),\n",
              " ('i', 3038),\n",
              " ('to', 2826),\n",
              " ('of', 2781),\n",
              " ('a', 2700),\n",
              " ('in', 1826),\n",
              " ('that', 1767),\n",
              " ('it', 1749),\n",
              " ('you', 1577)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBIdhB76RXy5",
        "outputId": "d7a6755f-b87e-41d6-9038-9b4efb426120"
      },
      "source": [
        "#Exemplo que tem no Spark Documentation - DataFrame\n",
        "from pyspark.sql.functions import *\n",
        "wordCounts = txtDF.select(explode(split(txtDF.value, \"\\s+\")).alias(\"word\")).groupBy(\"word\").count()\n",
        "wordCounts.orderBy(['count'],ascending=False).show(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|word|count|\n",
            "+----+-----+\n",
            "| the| 5412|\n",
            "|    | 2799|\n",
            "| and| 2794|\n",
            "|  of| 2724|\n",
            "|  to| 2702|\n",
            "|   a| 2575|\n",
            "|   I| 2533|\n",
            "|  in| 1706|\n",
            "|that| 1557|\n",
            "| was| 1361|\n",
            "+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}