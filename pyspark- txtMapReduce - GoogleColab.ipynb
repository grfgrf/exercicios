{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sherlockMapReduce - PySparkColab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grfgrf/exercicios/blob/main/pyspark-%20txtMapReduce%20-%20GoogleColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp6i4txWWMw-",
        "outputId": "2f6d2b80-a1af-4d31-becf-b120d3cd942f"
      },
      "source": [
        "%%bash\n",
        "#***IFs apenas para o notebook não executar novamente em caso de run all cells.\n",
        "\n",
        "#verifica se openjdk está instalado\n",
        "if (dpkg -l | grep -qw openjdk-8-jdk-headless) then \n",
        "  echo \"Ja instalado - openjdk-8-jdk-headless\" \n",
        "else \n",
        "  apt-get install openjdk-8-jdk-headless -qq > /dev/null | echo \"openjdk-8-jdk-headless - instalado com sucesso\" \n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk-8-jdk-headless - instalado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKWPErew7HHg",
        "outputId": "a93bb165-2c96-4f10-cebe-dcbed3d11815"
      },
      "source": [
        "%%bash\n",
        "#download spark-hadoop\n",
        "if [ -f \"spark-3.2.0-bin-hadoop3.2.tgz\" ]; then\n",
        "  echo \"Ja baixado - spark-3.2.0-bin-hadoop3.2.tgz\"\n",
        "else \n",
        "  wget -q  https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz | echo \"spark-3.2.0-bin-hadoop3.2.tgz - baixado com sucesso\"\n",
        "fi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.0-bin-hadoop3.2.tgz - baixado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnOz9fC7HQ2",
        "outputId": "fa7a9328-ec79-44da-b912-65f0c5d1879a"
      },
      "source": [
        "%%bash\n",
        "#extrair spark-hadoop\n",
        "if [ -d \"spark-3.2.0-bin-hadoop3.2\" ]; then\n",
        "  echo \"Ja descompactado - Pasta spark-3.2.0-bin-hadoop3.2\"\n",
        "else \n",
        "  tar xf spark-3.2.0-bin-hadoop3.2.tgz | echo \"spark-3.2.0-bin-hadoop3.2.tgz - descompactado com sucesso\"\n",
        "fi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.0-bin-hadoop3.2.tgz - descompactado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VIRCV5z7Hb0",
        "outputId": "09125b61-9b35-43e0-b31b-c26b6b60fbc9"
      },
      "source": [
        "%%bash\n",
        "#download sherlock.txt\n",
        "if [ -f \"/content/sample_data/sherlock.txt\" ]; then\n",
        "  echo \"Ja baixado - sherlock.txt\"\n",
        "else \n",
        "  wget -q -O /content/sample_data/sherlock.txt https://www.gutenberg.org/files/1661/1661-0.txt | echo \"sherlock.txt - baixado com sucesso\"\n",
        "fi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sherlock.txt - baixado com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht_iWNwOPqrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb35a7e-9628-41ee-e25f-fea333b056d3"
      },
      "source": [
        "#usa folder do spark como lib pyspark\n",
        "try:\n",
        "    findspark\n",
        "except NameError:\n",
        "    !pip install -q findspark\n",
        "    import findspark\n",
        "    findspark.init('spark-3.2.0-bin-hadoop3.2')\n",
        "    print(\"findspark - instalado com sucesso \")\n",
        "else:\n",
        "    print(\"já instalado - findspark\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "findspark - instalado com sucesso \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWvBZvULP8bV"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7h1_G0zBLbZ"
      },
      "source": [
        "#cria session e lê sherlock como .rdd\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "\n",
        "#dataframe\n",
        "txtDF = spark.read.format('text').load('/content/sample_data/sherlock.txt')\n",
        "\n",
        "#RDD\n",
        "txtRDD= spark.read.format('text').load('/content/sample_data/sherlock.txt').rdd\n",
        "\n",
        "#Texto inteiro em RDD com 1 row [k,v]\n",
        "rddSherlock = spark.sparkContext.wholeTextFiles('/content/sample_data/sherlock.txt',use_unicode=True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s_U1mQtEZQ_",
        "outputId": "dba17ce1-0f14-4bbc-fed5-e01985cfd02f"
      },
      "source": [
        "txtDF.head(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='The Project Gutenberg eBook of The Adventures of Sherlock Holmes, by Arthur Conan Doyle'),\n",
              " Row(value='')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLUTxmGHUhLM",
        "outputId": "ead0e5b9-b76f-4d22-eef6-7d28e00aca82"
      },
      "source": [
        "txtRDD.take(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(value='The Project Gutenberg eBook of The Adventures of Sherlock Holmes, by Arthur Conan Doyle'),\n",
              " Row(value='')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEClBJC9w-n_"
      },
      "source": [
        "#Mapeia só [\\W]+ lower case\n",
        "import re\n",
        "\n",
        "mapSherlock = rddSherlock.map(lambda x : re.sub(r\"[\\W]+\",\" \",x[1].lower()))\n",
        "#mapSherlock.take(1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is3P5Fs8-crA",
        "outputId": "15d44026-fe29-4326-8b0f-08d660185c0f"
      },
      "source": [
        "#Split por espaço em branco\n",
        "palavrasSherlock = mapSherlock.flatMap(lambda x: x.split(\" \"))\n",
        "palavrasSherlock.take(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'the', 'project', 'gutenberg', 'ebook']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC-iiDyKx_on",
        "outputId": "b58a0aec-eddc-458b-c528-fbd47a8d1f7e"
      },
      "source": [
        "#Adiciona coluna com valor 1 para reduce\n",
        "formatadoSherlock = palavrasSherlock.map(lambda z: (z,1)) \n",
        "formatadoSherlock.take(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 1), ('the', 1), ('project', 1), ('gutenberg', 1), ('ebook', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X33OFau2ydi1",
        "outputId": "81283dea-1c46-4b76-a88f-2b93adadff02"
      },
      "source": [
        "# RDD final com ReduceByKey (reduz keys iguais e soma values)\n",
        "finalSherlock = formatadoSherlock.reduceByKey(lambda a,b: a+b)\n",
        "finalSherlock.take(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 2), ('the', 5815), ('project', 89), ('gutenberg', 98), ('ebook', 13)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2jOqG9ZyxPp",
        "outputId": "ceabf774-19b1-47ba-df87-7f31c1c956d5"
      },
      "source": [
        "#lista TOP 10 sorted\n",
        "#contagem final depende da regra para definir \"O que é uma palavra?\"\n",
        "finalSherlock.sortBy(lambda x: x[1],ascending=False).collect()[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 5815),\n",
              " ('and', 3085),\n",
              " ('i', 3038),\n",
              " ('to', 2826),\n",
              " ('of', 2781),\n",
              " ('a', 2700),\n",
              " ('in', 1826),\n",
              " ('that', 1767),\n",
              " ('it', 1749),\n",
              " ('you', 1577)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBIdhB76RXy5",
        "outputId": "0aa863d6-c0bc-4f82-d0f3-57bca0758c2e"
      },
      "source": [
        "#Exemplo que tem no Spark Documentation - DataFrame\n",
        "from pyspark.sql.functions import *\n",
        "wordCounts = txtDF.select(explode(split(txtDF.value, \"\\s+\")).alias(\"word\")).groupBy(\"word\").count()\n",
        "wordCounts.orderBy(['count'],ascending=False).show(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|word|count|\n",
            "+----+-----+\n",
            "| the| 5412|\n",
            "|    | 2799|\n",
            "| and| 2794|\n",
            "|  of| 2724|\n",
            "|  to| 2702|\n",
            "|   a| 2575|\n",
            "|   I| 2533|\n",
            "|  in| 1706|\n",
            "|that| 1557|\n",
            "| was| 1361|\n",
            "+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}